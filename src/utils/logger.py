#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æ—¥å¿—é…ç½®æ¨¡å—
æä¾›ç»Ÿä¸€çš„æ—¥å¿—è®°å½•åŠŸèƒ½ï¼Œæ›¿æ¢printè¯­å¥
"""

import os
import sys
import logging
import logging.handlers
from datetime import datetime
from typing import Optional


class ColoredFormatter(logging.Formatter):
    """å½©è‰²æ—¥å¿—æ ¼å¼åŒ–å™¨"""
    
    # é¢œè‰²ä»£ç 
    COLORS = {
        'DEBUG': '\033[36m',     # é’è‰²
        'INFO': '\033[32m',      # ç»¿è‰²
        'WARNING': '\033[33m',   # é»„è‰²
        'ERROR': '\033[31m',     # çº¢è‰²
        'CRITICAL': '\033[35m',  # ç´«è‰²
        'RESET': '\033[0m'       # é‡ç½®
    }
    
    def format(self, record):
        # æ·»åŠ é¢œè‰²
        if record.levelname in self.COLORS:
            record.levelname = f"{self.COLORS[record.levelname]}{record.levelname}{self.COLORS['RESET']}"
        
        return super().format(record)


def setup_logger(
    name: str = "VerifyVision",
    log_level: str = "INFO",
    log_file: Optional[str] = None,
    console_output: bool = True,
    max_file_size: int = 10 * 1024 * 1024,  # 10MB
    backup_count: int = 5
) -> logging.Logger:
    """
    è®¾ç½®æ—¥å¿—è®°å½•å™¨
    
    Args:
        name: æ—¥å¿—è®°å½•å™¨åç§°
        log_level: æ—¥å¿—çº§åˆ« (DEBUG, INFO, WARNING, ERROR, CRITICAL)
        log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä¸å†™å…¥æ–‡ä»¶
        console_output: æ˜¯å¦è¾“å‡ºåˆ°æ§åˆ¶å°
        max_file_size: æ—¥å¿—æ–‡ä»¶æœ€å¤§å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        backup_count: å¤‡ä»½æ–‡ä»¶æ•°é‡
    
    Returns:
        é…ç½®å¥½çš„æ—¥å¿—è®°å½•å™¨
    """
    # åˆ›å»ºæ—¥å¿—è®°å½•å™¨
    logger = logging.getLogger(name)
    logger.setLevel(getattr(logging, log_level.upper()))
    
    # æ¸…é™¤ç°æœ‰çš„å¤„ç†å™¨
    logger.handlers.clear()
    
    # åˆ›å»ºæ ¼å¼åŒ–å™¨
    file_formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    console_formatter = ColoredFormatter(
        '%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%H:%M:%S'
    )
    
    # æ§åˆ¶å°å¤„ç†å™¨
    if console_output:
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(getattr(logging, log_level.upper()))
        console_handler.setFormatter(console_formatter)
        logger.addHandler(console_handler)
    
    # æ–‡ä»¶å¤„ç†å™¨
    if log_file:
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        log_dir = os.path.dirname(log_file)
        if log_dir:
            os.makedirs(log_dir, exist_ok=True)
        
        # ä½¿ç”¨RotatingFileHandlerå®ç°æ—¥å¿—è½®è½¬
        file_handler = logging.handlers.RotatingFileHandler(
            log_file,
            maxBytes=max_file_size,
            backupCount=backup_count,
            encoding='utf-8'
        )
        file_handler.setLevel(logging.DEBUG)  # æ–‡ä»¶è®°å½•æ‰€æœ‰çº§åˆ«
        file_handler.setFormatter(file_formatter)
        logger.addHandler(file_handler)
    
    return logger


def get_logger(name: str = "VerifyVision") -> logging.Logger:
    """
    è·å–æ—¥å¿—è®°å½•å™¨å®ä¾‹
    
    Args:
        name: æ—¥å¿—è®°å½•å™¨åç§°
    
    Returns:
        æ—¥å¿—è®°å½•å™¨å®ä¾‹
    """
    return logging.getLogger(name)


# åˆ›å»ºé»˜è®¤çš„æ—¥å¿—è®°å½•å™¨
default_logger = setup_logger(
    name="VerifyVision",
    log_level="INFO",
    log_file=os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "logs", "training.log"),
    console_output=True
)


# ä¾¿æ·å‡½æ•°
def log_info(message: str, logger: Optional[logging.Logger] = None):
    """è®°å½•ä¿¡æ¯æ—¥å¿—"""
    if logger is None:
        logger = default_logger
    logger.info(message)


def log_warning(message: str, logger: Optional[logging.Logger] = None):
    """è®°å½•è­¦å‘Šæ—¥å¿—"""
    if logger is None:
        logger = default_logger
    logger.warning(message)


def log_error(message: str, logger: Optional[logging.Logger] = None):
    """è®°å½•é”™è¯¯æ—¥å¿—"""
    if logger is None:
        logger = default_logger
    logger.error(message)


def log_debug(message: str, logger: Optional[logging.Logger] = None):
    """è®°å½•è°ƒè¯•æ—¥å¿—"""
    if logger is None:
        logger = default_logger
    logger.debug(message)


def log_critical(message: str, logger: Optional[logging.Logger] = None):
    """è®°å½•ä¸¥é‡é”™è¯¯æ—¥å¿—"""
    if logger is None:
        logger = default_logger
    logger.critical(message)


# è®­ç»ƒè¿›åº¦æ—¥å¿—è®°å½•å™¨
class TrainingProgressLogger:
    """è®­ç»ƒè¿›åº¦æ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, logger: Optional[logging.Logger] = None):
        self.logger = logger or default_logger
        self.start_time = None
        self.epoch_start_time = None
    
    def start_training(self, total_epochs: int, model_name: str, device: str):
        """å¼€å§‹è®­ç»ƒ"""
        self.start_time = datetime.now()
        self.logger.info("=" * 60)
        self.logger.info(f"å¼€å§‹è®­ç»ƒæ¨¡å‹: {model_name}")
        self.logger.info(f"è®­ç»ƒè®¾å¤‡: {device}")
        self.logger.info(f"æ€»è®­ç»ƒè½®æ•°: {total_epochs}")
        self.logger.info("=" * 60)
    
    def start_epoch(self, epoch: int, total_epochs: int):
        """å¼€å§‹æ–°çš„è®­ç»ƒè½®"""
        self.epoch_start_time = datetime.now()
        self.logger.info(f"å¼€å§‹ç¬¬ {epoch+1}/{total_epochs} è½®è®­ç»ƒ")
    
    def log_epoch_results(self, epoch: int, train_loss: float, train_acc: float, 
                         val_loss: float, val_acc: float, lr: float):
        """è®°å½•è½®æ¬¡ç»“æœ"""
        epoch_time = datetime.now() - self.epoch_start_time
        self.logger.info(f"ç¬¬ {epoch+1} è½®å®Œæˆ (è€—æ—¶: {epoch_time.total_seconds():.1f}s)")
        self.logger.info(f"  è®­ç»ƒ - æŸå¤±: {train_loss:.4f}, å‡†ç¡®ç‡: {train_acc:.2f}%")
        self.logger.info(f"  éªŒè¯ - æŸå¤±: {val_loss:.4f}, å‡†ç¡®ç‡: {val_acc:.2f}%")
        self.logger.info(f"  å­¦ä¹ ç‡: {lr:.6f}")
    
    def log_best_model(self, val_acc: float):
        """è®°å½•æœ€ä½³æ¨¡å‹ä¿å­˜"""
        self.logger.info(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%)")
    
    def finish_training(self, best_val_acc: float):
        """å®Œæˆè®­ç»ƒ"""
        total_time = datetime.now() - self.start_time
        self.logger.info("=" * 60)
        self.logger.info(f"è®­ç»ƒå®Œæˆ! æ€»è€—æ—¶: {total_time.total_seconds()/60:.2f} åˆ†é’Ÿ")
        self.logger.info(f"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")
        self.logger.info("=" * 60)


# è¯„ä¼°è¿›åº¦æ—¥å¿—è®°å½•å™¨
class EvaluationProgressLogger:
    """è¯„ä¼°è¿›åº¦æ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, logger: Optional[logging.Logger] = None):
        self.logger = logger or default_logger
    
    def start_evaluation(self, model_name: str, checkpoint_path: str, device: str):
        """å¼€å§‹è¯„ä¼°"""
        self.logger.info("=" * 60)
        self.logger.info(f"å¼€å§‹è¯„ä¼°æ¨¡å‹: {model_name}")
        self.logger.info(f"æ£€æŸ¥ç‚¹è·¯å¾„: {checkpoint_path}")
        self.logger.info(f"è¯„ä¼°è®¾å¤‡: {device}")
        self.logger.info("=" * 60)
    
    def log_evaluation_results(self, test_loss: float, accuracy: float, 
                              precision: float, recall: float, f1_score: float, auc: float):
        """è®°å½•è¯„ä¼°ç»“æœ"""
        self.logger.info("=" * 60)
        self.logger.info("è¯„ä¼°ç»“æœ:")
        self.logger.info(f"  æµ‹è¯•æŸå¤±: {test_loss:.4f}")
        self.logger.info(f"  æµ‹è¯•å‡†ç¡®ç‡: {accuracy:.2f}%")
        self.logger.info(f"  ç²¾ç¡®ç‡: {precision:.4f}")
        self.logger.info(f"  å¬å›ç‡: {recall:.4f}")
        self.logger.info(f"  F1åˆ†æ•°: {f1_score:.4f}")
        self.logger.info(f"  AUC: {auc:.4f}")
        self.logger.info("=" * 60)
    
    def finish_evaluation(self, results_dir: str):
        """å®Œæˆè¯„ä¼°"""
        self.logger.info(f"è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: {results_dir}")


if __name__ == "__main__":
    # æµ‹è¯•æ—¥å¿—åŠŸèƒ½
    logger = setup_logger("TestLogger", "DEBUG")
    
    logger.debug("è¿™æ˜¯è°ƒè¯•ä¿¡æ¯")
    logger.info("è¿™æ˜¯æ™®é€šä¿¡æ¯")
    logger.warning("è¿™æ˜¯è­¦å‘Šä¿¡æ¯")
    logger.error("è¿™æ˜¯é”™è¯¯ä¿¡æ¯")
    logger.critical("è¿™æ˜¯ä¸¥é‡é”™è¯¯ä¿¡æ¯")
    
    # æµ‹è¯•è¿›åº¦è®°å½•å™¨
    progress_logger = TrainingProgressLogger(logger)
    progress_logger.start_training(10, "EfficientNet-B0", "cpu")
    progress_logger.start_epoch(0, 10)
    progress_logger.log_epoch_results(0, 0.5, 85.0, 0.4, 90.0, 0.001)
    progress_logger.log_best_model(90.0)
    progress_logger.finish_training(90.0)
